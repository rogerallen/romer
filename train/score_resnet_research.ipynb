{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rallen/anaconda3/envs/dl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "# not using keras version since it cannot have an input size < 197x197.  Might also require 3-channel color.\n",
    "import keras\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "import resnet\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "tf\n"
     ]
    }
   ],
   "source": [
    "#K.image_data_format()\n",
    "print(keras.backend.image_data_format())\n",
    "print(keras.backend.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10078, 120, 32, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data/train3'\n",
    "train_input_image_names = glob(train_path+'/crop_score*png')\n",
    "train_input_image_names.sort()\n",
    "train_input_images = np.stack([np.array(Image.open(fn)) for fn in train_input_image_names])\n",
    "train_input_images.shape = train_input_images.shape + (1,)\n",
    "num_train_images,rows,cols,channels = train_input_images.shape\n",
    "num_train_images,rows,cols,channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 120, 32, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_path = 'data/valid3'\n",
    "valid_input_image_names = glob(valid_path+'/crop_score*png')\n",
    "valid_input_image_names.sort()\n",
    "valid_input_images = np.stack([np.array(Image.open(fn)) for fn in valid_input_image_names])\n",
    "valid_input_images.shape = valid_input_images.shape + (1,)\n",
    "num_valid_images,rows,cols,channels = valid_input_images.shape\n",
    "num_valid_images,rows,cols,channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_json = 'data/train3/crop_score_info.json'\n",
    "with open(results_json,'r') as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "for train_name in train_input_image_names:\n",
    "    index = int(train_name.split('.')[0].split('_')[-1])\n",
    "    train_indices.append(index)\n",
    "valid_indices = []\n",
    "for valid_name in valid_input_image_names:\n",
    "    index = int(valid_name.split('.')[0].split('_')[-1])\n",
    "    valid_indices.append(index)\n",
    "#train_indices[:20],valid_indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes = np.zeros(128+1,dtype=np.int32)\n",
    "lengths = np.zeros(16+1,dtype=np.int32)\n",
    "for ti in train_indices:\n",
    "    r = results[ti] # [84, 4] = \n",
    "    notes[r[0]] += 1\n",
    "    lengths[r[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HMM, realizing that MULTIPLE classes of output (note + length) are not \n",
    "# easily mapped here...going to need to look at this harder.  For now\n",
    "# let's just try to see if we can make due with 2 different models.\n",
    "#np.concatenate([lengths,notes])\n",
    "#NUM_CATEGORIES=128+1 + 16+1\n",
    "NUM_CATEGORIES=128+1 \n",
    "NUM_CATEGORIES1=16+1\n",
    "#train_results = np.zeros([len(train_indices),NUM_CATEGORIES],dtype=np.float32)\n",
    "train_results = np.zeros(len(train_indices),dtype=np.float32)\n",
    "train_results1 = np.zeros(len(train_indices),dtype=np.float32)\n",
    "i = 0\n",
    "for ti in train_indices:\n",
    "    r = results[ti]\n",
    "    #train_results[i,16+1+r[0]] = 1.0 # set note value\n",
    "    #train_results[i,r[1]] = 1.0 # set duration value\n",
    "    train_results[i] = r[0]\n",
    "    train_results1[i] = r[1]\n",
    "    i += 1\n",
    "train_results = np_utils.to_categorical(train_results,NUM_CATEGORIES)\n",
    "train_results1 = np_utils.to_categorical(train_results1,NUM_CATEGORIES1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10078, 129), (10078, 17))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.shape, train_results1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#valid_results = np.zeros([len(valid_indices),128+1 + 16+1],dtype=np.float32)\n",
    "valid_results = np.zeros(len(valid_indices),dtype=np.float32)\n",
    "valid_results1 = np.zeros(len(valid_indices),dtype=np.float32)\n",
    "i = 0\n",
    "for ti in valid_indices:\n",
    "    r = results[ti]\n",
    "    #valid_results[i,16+1+r[0]] = 1.0 # set note value\n",
    "    #valid_results[i,r[1]] = 1.0 # set duration value\n",
    "    valid_results[i] = r[0]\n",
    "    valid_results1[i] = r[1]\n",
    "    i += 1\n",
    "valid_results = np_utils.to_categorical(valid_results,NUM_CATEGORIES)\n",
    "valid_results1 = np_utils.to_categorical(valid_results1,NUM_CATEGORIES1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results[100], train_results1[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class score_generator(object):\n",
    "    \"\"\"X should be list of score images, Y should be a list of score results.  \n",
    "    Both should be the same length.\"\"\"\n",
    "    def __init__(self, X, Y, batch_size, channels):\n",
    "        self.X  = X\n",
    "        self.Y  = Y\n",
    "        self.bs = batch_size\n",
    "        self.channels = channels\n",
    "        self.i  = 0\n",
    "    def __next__(self):\n",
    "        xs = self.X[self.i:self.i+self.bs]\n",
    "        ys = self.Y[self.i:self.i+self.bs]\n",
    "        #ys = ys.reshape(len(ys),-1,1)\n",
    "        self.i = (self.i + self.bs) % self.X.shape[0]\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = score_generator(train_input_images, train_results, batch_size, channels)\n",
    "valid_generator = score_generator(valid_input_images, valid_results, batch_size, channels)\n",
    "train_generator1 = score_generator(train_input_images, train_results1, batch_size, channels)\n",
    "valid_generator1 = score_generator(valid_input_images, valid_results1, batch_size, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = resnet.ResnetBuilder.build_resnet_18((64, 64, 1), 128) # Total params: 11,444,288\n",
    "#model = resnet.ResnetBuilder.build_resnet_34((64, 64, 1), 128) # Total params: 21,563,584\n",
    "#model = resnet.ResnetBuilder.build_resnet_50((64, 64, 1), 128) # Total params: 24,025,920\n",
    "image_shape = (rows,cols,channels)\n",
    "model = resnet.ResnetBuilder.build_resnet_18(image_shape, NUM_CATEGORIES)\n",
    "model1 = resnet.ResnetBuilder.build_resnet_18(image_shape, NUM_CATEGORIES1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 120, 32, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 60, 16, 64)   3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 60, 16, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 60, 16, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 8, 64)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 30, 8, 64)    36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 30, 8, 64)    256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 30, 8, 64)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 8, 64)    36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 8, 64)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 8, 64)    256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 8, 64)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 30, 8, 64)    36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 30, 8, 64)    256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 8, 64)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 30, 8, 64)    36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 30, 8, 64)    0           add_1[0][0]                      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 30, 8, 64)    256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 30, 8, 64)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 4, 128)   73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 4, 128)   512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 4, 128)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 4, 128)   8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 4, 128)   147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 15, 4, 128)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 4, 128)   512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 4, 128)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 4, 128)   147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 4, 128)   512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 4, 128)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 4, 128)   147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 15, 4, 128)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 4, 128)   512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 4, 128)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 2, 256)    295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 2, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 2, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 2, 256)    33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 2, 256)    590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 2, 256)    0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 2, 256)    1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 2, 256)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 2, 256)    590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 2, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 2, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 2, 256)    590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 2, 256)    0           add_5[0][0]                      \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 2, 256)    1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 2, 256)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 1, 512)    1180160     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 1, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 1, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 1, 512)    131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 1, 512)    2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 1, 512)    0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 1, 512)    2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 1, 512)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 1, 512)    2359808     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 1, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 1, 512)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 1, 512)    2359808     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 1, 512)    0           add_7[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 1, 512)    2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 1, 512)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 129)          66177       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,247,233\n",
      "Trainable params: 11,239,425\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rate  = 1e-4\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(train_rate),\n",
    "              metrics=[\"accuracy\"])\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(train_rate),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 15s - loss: 1.7527 - acc: 0.7923 - val_loss: 0.9854 - val_acc: 0.8705\n",
      "Epoch 2/25\n",
      " - 13s - loss: 0.8229 - acc: 0.9266 - val_loss: 0.7455 - val_acc: 0.9387\n",
      "Epoch 3/25\n",
      " - 13s - loss: 0.6393 - acc: 0.9813 - val_loss: 0.6121 - val_acc: 0.9747\n",
      "Epoch 4/25\n",
      " - 13s - loss: 0.5655 - acc: 0.9931 - val_loss: 0.5642 - val_acc: 0.9832\n",
      "Epoch 5/25\n",
      " - 13s - loss: 0.5192 - acc: 0.9934 - val_loss: 0.5349 - val_acc: 0.9825\n",
      "Epoch 6/25\n",
      " - 14s - loss: 0.4730 - acc: 0.9945 - val_loss: 0.4910 - val_acc: 0.9816\n",
      "Epoch 7/25\n",
      " - 13s - loss: 0.4300 - acc: 0.9944 - val_loss: 0.4762 - val_acc: 0.9789\n",
      "Epoch 8/25\n",
      " - 13s - loss: 0.3980 - acc: 0.9967 - val_loss: 0.4080 - val_acc: 0.9864\n",
      "Epoch 9/25\n",
      " - 14s - loss: 0.3633 - acc: 0.9975 - val_loss: 0.3868 - val_acc: 0.9852\n",
      "Epoch 10/25\n",
      " - 13s - loss: 0.3395 - acc: 0.9971 - val_loss: 0.3824 - val_acc: 0.9819\n",
      "Epoch 11/25\n",
      " - 13s - loss: 0.3163 - acc: 0.9975 - val_loss: 0.3382 - val_acc: 0.9891\n",
      "Epoch 12/25\n",
      " - 13s - loss: 0.2816 - acc: 0.9989 - val_loss: 0.3078 - val_acc: 0.9870\n",
      "Epoch 13/25\n",
      " - 13s - loss: 0.2675 - acc: 0.9970 - val_loss: 0.2748 - val_acc: 0.9894\n",
      "Epoch 14/25\n",
      " - 13s - loss: 0.2383 - acc: 0.9980 - val_loss: 0.2491 - val_acc: 0.9915\n",
      "Epoch 15/25\n",
      " - 13s - loss: 0.2291 - acc: 0.9969 - val_loss: 0.2393 - val_acc: 0.9921\n",
      "Epoch 16/25\n",
      " - 13s - loss: 0.2066 - acc: 0.9984 - val_loss: 0.2552 - val_acc: 0.9849\n",
      "Epoch 17/25\n",
      " - 13s - loss: 0.1944 - acc: 0.9980 - val_loss: 0.2008 - val_acc: 0.9927\n",
      "Epoch 18/25\n",
      " - 13s - loss: 0.1890 - acc: 0.9973 - val_loss: 0.2165 - val_acc: 0.9861\n",
      "Epoch 19/25\n",
      " - 13s - loss: 0.1784 - acc: 0.9977 - val_loss: 0.1985 - val_acc: 0.9921\n",
      "Epoch 20/25\n",
      " - 13s - loss: 0.1759 - acc: 0.9970 - val_loss: 0.1812 - val_acc: 0.9930\n",
      "Epoch 21/25\n",
      " - 13s - loss: 0.1653 - acc: 0.9981 - val_loss: 0.2227 - val_acc: 0.9849\n",
      "Epoch 22/25\n",
      " - 13s - loss: 0.1645 - acc: 0.9969 - val_loss: 0.1869 - val_acc: 0.9873\n",
      "Epoch 23/25\n",
      " - 13s - loss: 0.1644 - acc: 0.9962 - val_loss: 0.1722 - val_acc: 0.9927\n",
      "Epoch 24/25\n",
      " - 13s - loss: 0.1562 - acc: 0.9969 - val_loss: 0.1889 - val_acc: 0.9894\n",
      "Epoch 25/25\n",
      " - 13s - loss: 0.1482 - acc: 0.9972 - val_loss: 0.1533 - val_acc: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ef6734780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "model.fit_generator(train_generator,\n",
    "                    num_train_images//batch_size, num_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=num_valid_images//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 15s - loss: 1.3490 - acc: 0.8010 - val_loss: 1.0109 - val_acc: 0.8618\n",
      "Epoch 2/25\n",
      " - 13s - loss: 0.7506 - acc: 0.9329 - val_loss: 0.8610 - val_acc: 0.9179\n",
      "Epoch 3/25\n",
      " - 13s - loss: 0.6167 - acc: 0.9748 - val_loss: 0.7947 - val_acc: 0.9402\n",
      "Epoch 4/25\n",
      " - 13s - loss: 0.5532 - acc: 0.9886 - val_loss: 0.7503 - val_acc: 0.9465\n",
      "Epoch 5/25\n",
      " - 13s - loss: 0.5114 - acc: 0.9922 - val_loss: 0.7092 - val_acc: 0.9546\n",
      "Epoch 6/25\n",
      " - 13s - loss: 0.4716 - acc: 0.9939 - val_loss: 0.7304 - val_acc: 0.9467\n",
      "Epoch 7/25\n",
      " - 13s - loss: 0.4350 - acc: 0.9967 - val_loss: 0.6732 - val_acc: 0.9566\n",
      "Epoch 8/25\n",
      " - 13s - loss: 0.4080 - acc: 0.9969 - val_loss: 0.5452 - val_acc: 0.9714\n",
      "Epoch 9/25\n",
      " - 13s - loss: 0.3830 - acc: 0.9964 - val_loss: 0.5833 - val_acc: 0.9590\n",
      "Epoch 10/25\n",
      " - 13s - loss: 0.3599 - acc: 0.9974 - val_loss: 0.5658 - val_acc: 0.9626\n",
      "Epoch 11/25\n",
      " - 13s - loss: 0.3281 - acc: 0.9973 - val_loss: 0.5423 - val_acc: 0.9653\n",
      "Epoch 12/25\n",
      " - 13s - loss: 0.3035 - acc: 0.9981 - val_loss: 0.5182 - val_acc: 0.9710\n",
      "Epoch 13/25\n",
      " - 13s - loss: 0.2962 - acc: 0.9951 - val_loss: 0.5246 - val_acc: 0.9698\n",
      "Epoch 14/25\n",
      " - 13s - loss: 0.2786 - acc: 0.9977 - val_loss: 0.4654 - val_acc: 0.9647\n",
      "Epoch 15/25\n",
      " - 13s - loss: 0.2678 - acc: 0.9974 - val_loss: 0.4666 - val_acc: 0.9656\n",
      "Epoch 16/25\n",
      " - 13s - loss: 0.2470 - acc: 0.9984 - val_loss: 0.4249 - val_acc: 0.9680\n",
      "Epoch 17/25\n",
      " - 13s - loss: 0.2388 - acc: 0.9961 - val_loss: 0.4375 - val_acc: 0.9640\n",
      "Epoch 18/25\n",
      " - 13s - loss: 0.2170 - acc: 0.9986 - val_loss: 0.3577 - val_acc: 0.9704\n",
      "Epoch 19/25\n",
      " - 13s - loss: 0.2031 - acc: 0.9982 - val_loss: 0.4116 - val_acc: 0.9592\n",
      "Epoch 20/25\n",
      " - 13s - loss: 0.1988 - acc: 0.9969 - val_loss: 0.3622 - val_acc: 0.9610\n",
      "Epoch 21/25\n",
      " - 13s - loss: 0.1874 - acc: 0.9978 - val_loss: 0.3725 - val_acc: 0.9713\n",
      "Epoch 22/25\n",
      " - 13s - loss: 0.1827 - acc: 0.9969 - val_loss: 0.4215 - val_acc: 0.9722\n",
      "Epoch 23/25\n",
      " - 13s - loss: 0.1698 - acc: 0.9985 - val_loss: 0.3305 - val_acc: 0.9661\n",
      "Epoch 24/25\n",
      " - 14s - loss: 0.1667 - acc: 0.9978 - val_loss: 0.2874 - val_acc: 0.9752\n",
      "Epoch 25/25\n",
      " - 13s - loss: 0.1615 - acc: 0.9974 - val_loss: 0.3626 - val_acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ef66cd748>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(train_generator1,\n",
    "                    num_train_images//batch_size, num_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=valid_generator1,\n",
    "                    validation_steps=num_valid_images//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 120, 32, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = 'data/test3'\n",
    "test_input_image_names = glob(test_path+'/crop_score*png')\n",
    "test_input_image_names.sort()\n",
    "test_input_images = np.stack([np.array(Image.open(fn)) for fn in test_input_image_names])\n",
    "test_input_images.shape = test_input_images.shape + (1,)\n",
    "num_test_images,rows,cols,channels = test_input_images.shape\n",
    "num_test_images,rows,cols,channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_indices = []\n",
    "for test_name in test_input_image_names:\n",
    "    index = int(test_name.split('.')[0].split('_')[-1])\n",
    "    test_indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = np.zeros(len(test_indices),dtype=np.float32)\n",
    "test_results1 = np.zeros(len(test_indices),dtype=np.float32)\n",
    "i = 0\n",
    "for ti in test_indices:\n",
    "    r = results[ti]\n",
    "    test_results[i] = r[0]\n",
    "    test_results1[i] = r[1]\n",
    "    i += 1\n",
    "test_results = np_utils.to_categorical(test_results,NUM_CATEGORIES)\n",
    "test_results1 = np_utils.to_categorical(test_results1,NUM_CATEGORIES1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_generator = score_generator(test_input_images, test_results, batch_size, channels)\n",
    "test_generator1 = score_generator(test_input_images, test_results1, batch_size, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16556710133758876, 0.99038461538461542]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator,steps=num_test_images//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32224668462115985, 0.96875]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate_generator(test_generator1,steps=num_test_images//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not bad!  Definitely overfitting going on, but to be expected with not a huge amount of training data.\n",
    "# prev. comment was before 4x data.  Now getting great correlation after just 25 iters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
