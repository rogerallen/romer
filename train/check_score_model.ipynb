{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rallen/anaconda3/envs/dl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import RMSprop \n",
    "\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes_model_file   = 'data/results/note_model_180114.json'\n",
    "notes_weights_file = 'data/results/note_mask_weights_180114_120637.h5'\n",
    "with open(notes_model_file,\"r\") as f:\n",
    "    json_string = f.read()\n",
    "notes_model = model_from_json(json_string)\n",
    "notes_model.load_weights(notes_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_model_file   = 'data/results/length_model_180114.json'\n",
    "length_weights_file = 'data/results/length_mask_weights_180114_120637.h5'\n",
    "with open(length_model_file,\"r\") as f:\n",
    "    json_string = f.read()\n",
    "length_model = model_from_json(json_string)\n",
    "length_model.load_weights(length_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(base_name):\n",
    "    notes = []\n",
    "    with open(f'../setup/{base_name}.rmf') as csvfile:\n",
    "        for row in csv.reader(csvfile):\n",
    "            if row[0] == 'note':\n",
    "                notes.append(row[1:])  \n",
    "    return notes\n",
    "\n",
    "def get_notes_lengths(note_pred,length_pred):\n",
    "    assert(note_pred.shape[0] == length_pred.shape[0])\n",
    "    num_preds = note_pred.shape[0]\n",
    "    notes_lengths = []\n",
    "    for i in range(num_preds):\n",
    "        note_class = note_pred[i].argmax()\n",
    "        length_class = length_pred[i].argmax()\n",
    "        note_confidence = note_pred[i,note_class]\n",
    "        #if note_confidence > 0.99:\n",
    "        #    note_confidence = \"high\"\n",
    "        #elif note_confidence > 0.8:\n",
    "        #    note_confidence = \"med\"\n",
    "        #else:\n",
    "        #    note_confidence = \"low\"\n",
    "        note_index = note_class-2\n",
    "        note_name = \"C C# D D# E F F# G G# A A# B\".split()[note_index % 12]\n",
    "        note_octave = int(note_index/12) - 2\n",
    "        if note_index == -2:\n",
    "            note_name = 'X'\n",
    "            note_octave = 0\n",
    "        elif note_index == -1:\n",
    "            note_name = 'R'\n",
    "            note_octave = 0\n",
    "        length_confidence = length_pred[i,length_class]\n",
    "        #if length_confidence > 0.99:\n",
    "        #    length_confidence = \"high\"\n",
    "        #elif length_confidence > 0.8:\n",
    "        #    length_confidence = \"med\"\n",
    "        #else:\n",
    "        #    length_confidence = \"low\"\n",
    "        length = length_class/4\n",
    "        if note_index == -2 and note_confidence > 0.8:#note_confidence != \"low\":\n",
    "            continue # no note\n",
    "        notes_lengths.append([i,\n",
    "                              (note_index,note_name,note_octave,note_confidence),\n",
    "                              (length, length_confidence)])\n",
    "    return notes_lengths\n",
    "\n",
    "def refine_notes_lengths(raw_notes_lengths):\n",
    "    notes_lengths = []\n",
    "    cur = []\n",
    "    last_index = -100\n",
    "    for x in raw_notes_lengths:\n",
    "        if x[0] == last_index + 1:\n",
    "            cur.append(x[1:])\n",
    "        else:\n",
    "            num_samples = len(cur)\n",
    "            if num_samples > 0:\n",
    "                conf = np.zeros(num_samples)\n",
    "                for i,c in enumerate(cur):\n",
    "                    conf[i] = c[0][-1]\n",
    "                mci = conf.argmax()\n",
    "                notes_lengths.append((cur[mci][0][0],cur[mci][1][0]))\n",
    "            cur = []\n",
    "        last_index = x[0]\n",
    "    return notes_lengths\n",
    "\n",
    "def get_crop_inputs(cur_score_info):\n",
    "    img_crop_width = 32\n",
    "    img_step = 2\n",
    "    img_crop_height = int(cur_score_info['height'])\n",
    "    img_count = cur_score_info['width']//img_step\n",
    "    cur_img = Image.open('data/train2/' + cur_score_info['name'])\n",
    "    cur_crop_inputs = np.zeros((img_count,img_crop_height,img_crop_width,1),dtype='uint8')\n",
    "    for i in range(img_count):\n",
    "        img_x = i*img_step\n",
    "        cur_crop_img = cur_img.crop((img_x, 0, img_x + img_crop_width, img_crop_height))\n",
    "        cur_crop_inputs[i] = np.array(cur_crop_img).reshape(img_crop_height,img_crop_width,1)\n",
    "    return cur_crop_inputs \n",
    "\n",
    "# FIXME output to file\n",
    "def output_rmf(outfile,notes_lengths):\n",
    "    print(\"writing output to:\",outfile)\n",
    "    with open(outfile,'w') as f:\n",
    "        cur_beat = 0.0\n",
    "        #print(notes_lengths)\n",
    "        for (n,l) in notes_lengths:\n",
    "            print(\"note,%d,%f,%f\"%(n,cur_beat,l),file=f)\n",
    "            cur_beat += l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strip_score_chromatic_00.png\n",
      "strip_score_gen_one_00.png\n",
      "writing output to: data/results/chromatic.rmf\n",
      "strip_score_gen_one_01.png\n",
      "strip_score_gen_one_02.png\n",
      "strip_score_gen_one_03.png\n",
      "strip_score_gen_one_04.png\n",
      "strip_score_gen_one_05.png\n",
      "strip_score_gen_one_06.png\n",
      "strip_score_gen_one_07.png\n",
      "strip_score_gen_two_00.png\n",
      "writing output to: data/results/gen_one.rmf\n",
      "strip_score_gen_two_01.png\n",
      "strip_score_gen_two_02.png\n",
      "strip_score_gen_two_03.png\n",
      "strip_score_gen_two_04.png\n",
      "strip_score_gen_two_05.png\n",
      "strip_score_gen_two_06.png\n",
      "strip_score_gen_two_07.png\n",
      "strip_score_gen_two_08.png\n",
      "strip_score_gen_two_09.png\n",
      "strip_score_gen_two_10.png\n",
      "strip_score_gen_two_11.png\n",
      "strip_score_twinkle_00.png\n",
      "writing output to: data/results/gen_two.rmf\n",
      "strip_score_twinkle_01.png\n",
      "writing output to: data/results/twinkle.rmf\n"
     ]
    }
   ],
   "source": [
    "with open(f\"data/train2/strip_score_info.json\", 'r') as infile:\n",
    "    score_info = json.load(infile)\n",
    "    \n",
    "last_base_name = \"\"\n",
    "score_notes_lengths = {}\n",
    "target_notes_lengths = {}\n",
    "for cur_score_info in score_info:\n",
    "    print(cur_score_info['name'])\n",
    "    cur_base_name = cur_score_info['base']\n",
    "    if cur_base_name != last_base_name:\n",
    "        if len(score_notes_lengths.get(last_base_name,[])) > 0:\n",
    "            rmf_filename = \"data/results/%s.rmf\"%(last_base_name)\n",
    "            output_rmf(rmf_filename,score_notes_lengths[last_base_name]) # FIXME\n",
    "        score_notes_lengths[cur_base_name] = []\n",
    "        target_notes_lengths[cur_base_name] = get_notes(cur_base_name)\n",
    "        last_base_name = cur_base_name\n",
    "    cur_crop_inputs = get_crop_inputs(cur_score_info)\n",
    "    # predict\n",
    "    note_preds   = notes_model.predict(cur_crop_inputs)\n",
    "    length_preds = length_model.predict(cur_crop_inputs)\n",
    "    raw = get_notes_lengths(note_preds,length_preds)\n",
    "    nl = refine_notes_lengths(raw)\n",
    "    #print(\"x\",nl)\n",
    "    score_notes_lengths[cur_base_name].extend(nl)\n",
    "rmf_filename = \"data/results/%s.rmf\"%(last_base_name)\n",
    "output_rmf(rmf_filename,score_notes_lengths[last_base_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
