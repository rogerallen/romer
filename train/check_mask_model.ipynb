{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import RMSprop\n",
    "from mask_utils import get_images, get_input_prediction_tiles, image_from_tiles\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class image_generator(object):\n",
    "    def __init__(self, X, Y, batch_size, channels):\n",
    "        self.X  = X\n",
    "        self.Y  = Y\n",
    "        self.bs = batch_size\n",
    "        self.channels = channels\n",
    "        self.i  = 0\n",
    "    def __next__(self):\n",
    "        xs = self.X[self.i:self.i+self.bs]\n",
    "        ys = self.Y[self.i:self.i+self.bs]\n",
    "        # convert 32,64,64,1 -> 32,4096,1\n",
    "        ys = ys.reshape(len(ys),-1,self.channels)\n",
    "        self.i = (self.i + self.bs) % self.X.shape[0]\n",
    "        return xs, ys\n",
    "\n",
    "def get_score_mask_images(path):\n",
    "    score_image_names = glob(path+'/diced_score*png')\n",
    "    mask_image_names = glob(path+'/diced_mask*png')\n",
    "    score_image_names.sort()\n",
    "    mask_image_names.sort()\n",
    "    score_images = np.stack([np.array(Image.open(fn)) for fn in score_image_names])\n",
    "    mask_images = np.stack([np.array(Image.open(fn))//255 for fn in mask_image_names])\n",
    "    score_images.shape = score_images.shape + (1,)\n",
    "    mask_images.shape = mask_images.shape + (1,)\n",
    "    assert(score_images.shape == mask_images.shape)\n",
    "    return score_images, mask_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model & weights that were most-recently created by train_mask_model.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file   = 'data/results/model_180106.json'\n",
    "weights_file = 'data/results/mask_weights_180106_143329.h5'\n",
    "\n",
    "#model_file   = 'data/results/model_171223.json'\n",
    "#weights_file = 'data/results/mask_weights_171223_134224.h5'\n",
    "# very interesting comparison.  Nomaxpool is WAY better than maxpool-enabled.\n",
    "#model_file   = 'data/results/model_171112.json'\n",
    "#weights_file = 'data/results/mask_weights_171112_123000.h5'\n",
    "\n",
    "with open(model_file,\"r\") as f:\n",
    "    json_string = f.read()\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of images to check vs. the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_images, train_mask_images = get_score_mask_images('data/train')\n",
    "valid_score_images, valid_mask_images = get_score_mask_images('data/valid')\n",
    "test_score_images, test_mask_images = get_score_mask_images('data/valid')\n",
    "num_train_images,rows,cols,channels = train_score_images.shape\n",
    "num_valid_images,_,_,_ = valid_score_images.shape\n",
    "num_test_images,_,_,_ = test_score_images.shape\n",
    "batch_size = 32\n",
    "train_generator = image_generator(train_score_images, train_mask_images,\n",
    "                                  batch_size, channels)\n",
    "valid_generator = image_generator(valid_score_images, valid_mask_images,\n",
    "                                  batch_size, channels)\n",
    "test_generator = image_generator(test_score_images, test_mask_images,\n",
    "                                  batch_size, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model & then evaluate it vs the validation & test sets. \n",
    "The validation score should match what you saw in the output of your training log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=RMSprop(1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0053708083116191319, 0.99939882989967188]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does this match your expectation?\n",
    "model.evaluate_generator(valid_generator,steps=num_valid_images//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005418685425822853, 0.99938681532227547]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are some images that were never seen by the model before.\n",
    "# we hope they get a score similar to the validation set.\n",
    "model.evaluate_generator(test_generator,steps=num_test_images//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now loop through the test cases, predicting the images and storing them as mask png files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting chromatic\n",
      "predicting gen_one\n",
      "predicting gen_two\n",
      "predicting twinkle\n"
     ]
    }
   ],
   "source": [
    "#for base_name in ['chromatic','chromatic_piano','gen_one','gen_two','twinkle']:\n",
    "for base_name in ['chromatic','gen_one','gen_two','twinkle']:\n",
    "    print(f\"predicting {base_name}\")\n",
    "    score_image, mask_image = get_images(base_name)\n",
    "    input_tiles = get_input_prediction_tiles(score_image)\n",
    "    pred_tiles = model.predict(input_tiles)\n",
    "    pred_one = image_from_tiles(score_image.width, score_image.height, \n",
    "                                input_tiles.shape[0], pred_tiles, 1)\n",
    "    #pred_one\n",
    "    with open(f\"data/results/pred_mask_{base_name}.png\",'wb') as f:\n",
    "        pred_one.save(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the predicted vs. expected images... You'll probably want to do this outside of Jupyter notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0AAAARACAAAAADir2wQAAAOqUlEQVR4nO3dy5bcuHkAYKBb8Xjh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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=832x1088 at 0x7F0BA748B6A0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzAAAAQgCAAAAAAcEubSAAAD2klEQVR4nO3TwQnAMAwEQSf995y0\n4IWIgJl5C3GfXQsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgG3X7Ptn9j18Zi+Fe3gFHEUw\nEAgGAsFAIBgIBAOBYCAQDASCgUAwEAgGAsFAIBgIBAOBYCAQDASCgUAwEAgGAsFAIBgIBAOBYCAQ\nDASCgUAwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcO2dPbMr4Hd7\nKdzDK+AogoFAMBAIBgLBQCAYCAQDgWAgEAwEgoFAMBAIBgLBQCAYCAQDgWAgEAwEgoFAMBAIBgLB\nQCAYCAQDgWAgEAwEggEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgOAFTo8C\na0tKXq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=816x1056 at 0x7F0BA74B9EF0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
